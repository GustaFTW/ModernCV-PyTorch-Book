{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Define the data\n",
    "x = [[1, 2], [3, 4], [5, 6], [7, 8]]\n",
    "y = [[3], [7], [11], [15]]\n",
    "X = torch.tensor(x).float().to(device)\n",
    "Y = torch.tensor(y).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataset class\n",
    "class Dataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = torch.tensor(x).float()\n",
    "        self.y = torch.tensor(y).float()\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "\n",
    "    def __getitem__(self, ix):\n",
    "        return self.x[ix], self.y[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10299/2996565822.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.x = torch.tensor(x).float()\n",
      "/tmp/ipykernel_10299/2996565822.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.y = torch.tensor(y).float()\n"
     ]
    }
   ],
   "source": [
    "# Instantiating the dataset and creating a dataloader\n",
    "ds = Dataset(X, Y)\n",
    "dl = DataLoader(ds, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor([[3.],\n",
      "        [7.]])\n",
      "tensor([[7., 8.],\n",
      "        [5., 6.]])\n",
      "tensor([[15.],\n",
      "        [11.]])\n"
     ]
    }
   ],
   "source": [
    "# Inspect the dataset\n",
    "for x, y in dl:\n",
    "    print(x)\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a neural network inheriting from nn.Module\n",
    "class Neural(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.input_to_hidden_layer = nn.Linear(2, 8)\n",
    "        self.activation_hidden_layer = nn.ReLU()\n",
    "        self.output_layer = nn.Linear(8, 1)\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.input_to_hidden_layer(x)\n",
    "        x = self.activation_hidden_layer(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import SGD\n",
    "\n",
    "# Instantiate the network\n",
    "mynet = Neural().to(device)\n",
    "\n",
    "# MSE for the loss function\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# SGD for optimizer and set it to update the model parameters\n",
    "optim = SGD(mynet.parameters(), lr = 10e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02000570297241211\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Train the network\n",
    "loss_history = []\n",
    "start = time.time()\n",
    "\n",
    "for _ in range(20):\n",
    "    for x, y in dl:\n",
    "        \n",
    "        # First zero the gradient\n",
    "        optim.zero_grad()\n",
    "\n",
    "        # Calculate the loss function\n",
    "        loss_value = loss_fn(mynet(x), y)\n",
    "\n",
    "        # Do the backward propagation\n",
    "        loss_value.backward()\n",
    "\n",
    "        # Step the optimizer\n",
    "        optim.step()\n",
    "\n",
    "        # Save the loss\n",
    "        loss_history.append(loss_value)\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[20.7034]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting with the model\n",
    "val_x = [[10, 11]]\n",
    "val_x = torch.tensor(val_x).float().to(device)\n",
    "\n",
    "# Pass the value through the model\n",
    "mynet(val_x)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(121.3294, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Use the same model/data that we used with the previous loss fn\n",
    "model = Neural().to(device)\n",
    "\n",
    "# Define the custom loss fn\n",
    "def my_MSE(_y, y): # _y predictions and y is the y true\n",
    "    loss = (_y-y)**2\n",
    "    loss = loss.mean()\n",
    "    return loss\n",
    "\n",
    "\n",
    "loss_value = my_MSE(model(X), Y)\n",
    "print(loss_value)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking the intermediate values of the model (values of a hidden layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class neuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.input_to_hidden_layer = nn.Linear(2, 8)\n",
    "        self.activation_hidden_layer = nn.ReLU()\n",
    "        self.output_layer = nn.Linear(8, 1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        hidden1 = self.input_to_hidden_layer(x)\n",
    "        hidden2 = self.activation_hidden_layer(hidden1)\n",
    "        output = self.output_layer(hidden2)\n",
    "        return output, hidden2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0391],\n",
      "        [-0.0334],\n",
      "        [-0.1058],\n",
      "        [-0.1782]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mynet = neuralNet().to(device)\n",
    "print(mynet(X)[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining a model using the sequential method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10299/2996565822.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.x = torch.tensor(x).float()\n",
      "/tmp/ipykernel_10299/2996565822.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.y = torch.tensor(y).float()\n"
     ]
    }
   ],
   "source": [
    "# Let's remember ourselves the dataset\n",
    "ds = Dataset(x, y)\n",
    "dl = DataLoader(ds, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the model using the sequential method\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(2, 8),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(8, 1)\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Linear: 1-1                            [-1, 8]                   24\n",
      "├─ReLU: 1-2                              [-1, 8]                   --\n",
      "├─Linear: 1-3                            [-1, 1]                   9\n",
      "==========================================================================================\n",
      "Total params: 33\n",
      "Trainable params: 33\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.00\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.00\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Linear: 1-1                            [-1, 8]                   24\n",
       "├─ReLU: 1-2                              [-1, 8]                   --\n",
       "├─Linear: 1-3                            [-1, 1]                   9\n",
       "==========================================================================================\n",
       "Total params: 33\n",
       "Trainable params: 33\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.00\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.00\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 0.00\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import and use the torch.summary\n",
    "from torchsummary import summary\n",
    "\n",
    "summary(model, torch.zeros(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.019675731658935547\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import SGD\n",
    "import time\n",
    "\n",
    "# Training the model\n",
    "loss_func = nn.MSELoss()\n",
    "optim = SGD(model.parameters(), lr=10e-4)\n",
    "start = time.time()\n",
    "loss_history = []\n",
    "for _ in range(50):\n",
    "    for ix, iy, in dl:\n",
    "        \n",
    "        # Zero grad for the optim\n",
    "        optim.zero_grad()\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = loss_func(model(ix), iy)\n",
    "        \n",
    "        # Do the backward propagation\n",
    "        loss.backward()\n",
    "\n",
    "        # Step the optimizer\n",
    "        optim.step()\n",
    "\n",
    "        # Save the loss\n",
    "        loss_history.append(loss_value)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[16.5398],\n",
       "        [20.3068],\n",
       "        [ 4.2971]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a validation dataset\n",
    "val = [[8, 9], [10, 11], [1.5, 2.5]]\n",
    "model(torch.tensor(val).float().to(device))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the model\n",
    "\n",
    "Always remember that when saving a model, is good practice to send it to cpu (if it is on GPU), because if the model is saved on GPU it'll save the tensors as CUDA tensors, and if the machine where the model is further loaded isn't compatible with CUDA you'll run into an error, so it's better to save it as a CPU tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model after sending it to CPU\n",
    "# !mkdir ./savedmodel/\n",
    "torch.save(model.to('cpu').state_dict(), './savedmodel/mymodel.pth')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[16.5398],\n",
       "        [20.3068],\n",
       "        [ 4.2971]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To load a model we need to have a model with the same structure\n",
    "# because we're only loading the model's weights\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(2, 8),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(8, 1)\n",
    ")\n",
    "\n",
    "# Load the model\n",
    "state_dict = torch.load(\"./savedmodel/mymodel.pth\")\n",
    "\n",
    "# Now we load the state_dict into our model\n",
    "print(model.load_state_dict(state_dict=state_dict))\n",
    "\n",
    "# Send it to device and make a prediction\n",
    "model.to(device)\n",
    "model(torch.tensor(val).float().to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch_book",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
